#
# Copyright (C) 2015 INRA
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#

[global]
# uncomment and set if not in the PATH, should be version = 4.4.3
#makeflow = <path>/cctools-4.4.3/bin/makeflow
# batch system type: local, condor, sge, moab, cluster, wq, hadoop, mpi-queue
batch_system_type = sge
# add these options to all batch submit files
batch_options = 
# add these options to limit the number of jobs sumitted in parallel
limit_submission = 100
# on which socket host should run the web server #NOT AVAILABLE for workflowBS
server_socket_host = 127.0.0.1
# on which socket port should run the web server #NOT AVAILABLE for workflowBS
server_socket_port = 8080
# date format
date_format = %d/%m/%Y

[email]
#NOT AVAILABLE for workflowBS
# if you want an email to be sent at the end of the workflow execution
# set the smtp_server and the from_address values
smtp_server = 
smtp_port = 
from_address = 
from_password = 
# uncomment and set if you want to use these values for all the workflow
# these variables can be overloaded within the workflow implementation by
# using self.set_to_address("address"), self.set_subject("subject"), 
# self.set_message("message") functions
#to_address =
#subject =
#message =

[storage]
# where should be written the log file
log_file = <path>/jflow.log
# Where should the pipelines write results, should be accessible 
# by all cluster nodes
work_directory = <path>/work
# Where should the pipelines write temporary files, should be 
# accessible by all cluster nodes
tmp_directory = <path>/tmp

[softwares]
# uncomment and set if not in the PATH
#fastqc=<path>/fastqc
#samtools = <path>/samtools-1.3/samtools
#trim_galore = <path>/trim_galore_v0.4.0/trim_galore
#bismark = <path>/bismark_v0.15.0/bismark
#bismark_genome_preparation = <path>/bismark_v0.15.0/bismark_genome_preparation
#deduplicate_bismark = <path>//bismark_v0.15.0/deduplicate_bismark
#bowtie2 =  <path>/bowtie2
#R > v3.2
#Rscript=<path>/R-3.2.2/bin/Rscript


[components]
# By default for SGE and local machine, the memory and the CPU are automaticaly retrieve from this file:
# For SGE use the standard option -pe parallel_XXX N -l mem=XG
#For local machine set cpu=X mem=XG
# For other scheduler default values are mentionned later they can be update in code.

Fastqc.batch_options = -pe parallel_smp 8 -l mem=3G -l h_vmem=5G -q workq

# BismarkGenomePreparation needs lot of memory
#BismarkGenomePreparation.batch_options = -l mem=20G -l h_vmem=20G -q workq

# Bismark launch 2 process of bowtie (or for if --non-directionnal) with HUGE_CPU 
# the option HUGE_CPU is divided by to to give bowtie access to HUGE_CPU/2 cpu
# Default : HUGE_CPU & NORMAL_MEM
#Bismark.batch_options = -pe parallel_smp 12 -l mem=2G -l h_vmem=4G -q workq

# Default : HUGE_CPU & LARGE_MEM
#RemoveDuplicate.batch_options = -l mem=8G -l h_vmem=10G -pe parallel_smp 12

# Default:  HUGE_CPU & LARGE_MEM
#SamtoolsSortSam.batch_options = -l mem=8G -l h_vmem=10G -pe parallel_smp 12

# Default : None
MethylationCalling.batch_options = -l mem=10G -l h_vmem=12G 
MethylKitDM.batch_options = -l mem=10G -l h_vmem=100G -pe parallel_smp 8 
DssDM.batch_options = -l mem=10G -l h_vmem=100G -pe parallel_smp 8 

# To avoid to be killed by scheduler uncoment and set appropriate memory 
# and cpu parameters for each component
# Can be increase in pipeline code : see workflows/methylseq/__init__.py and use class variable *_CPU & *_MEM
# NORMAL_MEM = "2G"
# LARGE_MEM = "8G"
# HUGE_MEM = "20G"
# NORMAL_CPU = 2
# LARGE_CPU = 8
# HUGE_CPU = 12


# Set workflows group
[workflows]

